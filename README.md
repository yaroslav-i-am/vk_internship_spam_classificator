# Исследование моделей для распознавания спама в англоязычных сообщениях

## Условие:
Дан тренировочный датасет с текстами сообщений из мессенджера на английском языке. Для каждого из них проставлен флаг того, является ли сообщение СПАМом. 
Так же дан тестовый датасет с такими же текстами сообщений, но без флага. Необходимо проскорить модель и приложить результаты.

## Данные
* `text_type` - целевая переменная, флаг СПАМ/не СПАМ
* `text` - текст сообщения. 

## Задача: 
* Провести базовую аналитику по имеющимся данным
* Обучить модель по тексту сообщения определять, является ли ее содержимое СПАМом (ожидается, что будут опробованы несколько подходов, из которых аргументированно выбирается наилучший; можно использовать любую библиотеку или фреймворк)
* Целевой метрикой при оценке работы модели будет `ROC-AUC score`
* Произвести скоринг лучшей моделью тестовых данных, а результат записать в csv-файл в виде таблицы с колонками `score` и `text`
* Выложить код на `juруtег notebook` и результирующий файл со скорами модели на [https://github.com] отдельным проектом и поделиться ссылкой в поле для ответа.

## Используемые DS-сущности:
* **Lightning** + **WandB**
* **PyTorch**
* **YaGPT** + **Yandex.Cloud**
* **CatBoost**
* **TfIdf** / **FastText**
* **K-Fold**

## Top-Метрики
| Модель / Векторизатор | Значение метрики |
|-|-|
| **LogisticRegression + TfIdf** | $0.9609115205143534$ |
| **CatBoost + TfIdf** | $0.9762115194855141$ |
| **torch.nn.Embedding + pooling + усреднение эмбеддингов + CNN** | $0.9803413151716367$ |
| **CatBoost + CatBoost-`text_features`** | $0.9882046766847703$ |
| **CatBoost + CatBoost-`text_features` + `text_stat` features** | $0.9918659794804257$ ($-0.0004$ со стеммингом)|

## Прочие эксперименты
| Модель / Векторизатор | Значение метрики |
|-|-|
| **fastText (Нативный _supervised_ классификатор)** | $0.6945184582939149$ |
| **YandexGPT-Pro API** | $0.817508499271491$ |

## Пути развития
Вопрос $\textemdash$ нужно ли это бизнесу, когда TfIdf на логистической регрессии выдаёт $0.961$? 

## Отсутствующие эксперименты
* LightGBM / XGBoost / RandomForest
* Стекинг и блендинг для tree-based моделей
* AutoML
* BERT finetuning
* YandexGPT finetuning
* Англоязычные LLM
* (Стемминг существенного прироста не даёт)

